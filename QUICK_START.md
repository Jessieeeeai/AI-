# IndexTTS2 å¿«é€Ÿéƒ¨ç½²æŒ‡å—

## ğŸš€ åœ¨ RunPod æœåŠ¡å™¨ä¸Šæ‰§è¡Œä»¥ä¸‹å‘½ä»¤

### ç¬¬ä¸€æ­¥ï¼šæ‹‰å–æœ€æ–°ä»£ç 
```bash
cd /workspace/videoai-pro
git pull origin main
```

### ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œéƒ¨ç½²è„šæœ¬
```bash
chmod +x deploy_indextts2.sh
./deploy_indextts2.sh
```

**é¢„è®¡æ—¶é—´**: 15-30 åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦ï¼‰

éƒ¨ç½²è¿‡ç¨‹åŒ…æ‹¬ï¼š
1. âœ… å®‰è£… `uv` åŒ…ç®¡ç†å™¨
2. âœ… å…‹éš† IndexTTS2 å®˜æ–¹ä»“åº“
3. âœ… å®‰è£… Python ä¾èµ–ï¼ˆPyTorch, torchaudio ç­‰ï¼‰
4. âœ… ä¸‹è½½ IndexTTS2 æ¨¡å‹ï¼ˆçº¦ 15GBï¼‰
5. âœ… åˆ›å»º Flask API æœåŠ¡å™¨
6. âœ… åˆ›å»ºå¯åŠ¨è„šæœ¬

### ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨æœåŠ¡
```bash
cd /workspace/index-tts
pm2 start start_service.sh --name indextts2 --interpreter bash
```

### ç¬¬å››æ­¥ï¼šéªŒè¯æœåŠ¡
```bash
# ç­‰å¾… 2-3 åˆ†é’Ÿè®©æ¨¡å‹åŠ è½½åˆ° GPU
sleep 120

# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:5000/health

# é¢„æœŸè¾“å‡º:
# {
#   "status": "healthy",
#   "mode": "production",
#   "device": "cuda:0",
#   "model_loaded": true,
#   "custom_voices": 0
# }
```

### ç¬¬äº”æ­¥ï¼šæµ‹è¯• TTS
```bash
curl -X POST http://localhost:5000/api/v1/tts \
  -H "Content-Type: application/json" \
  -d '{
    "text": "ä½ å¥½ï¼Œè¿™æ˜¯ IndexTTS2 æµ‹è¯•",
    "voiceId": "default"
  }' \
  -o test_tts.wav

# æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆåº”è¯¥ > 0ï¼‰
ls -lh test_tts.wav
```

### ç¬¬å…­æ­¥ï¼šè¿è¡Œæ•°æ®åº“è¿ç§»
```bash
cd /workspace/videoai-pro
node server/migrations/run.js
```

### ç¬¬ä¸ƒæ­¥ï¼šé‡å¯åç«¯
```bash
pm2 restart backend
pm2 logs backend --lines 50 --nostream
```

---

## âœ… å®Œæˆæ£€æŸ¥æ¸…å•

- [ ] IndexTTS2 ä»“åº“å…‹éš†æˆåŠŸ
- [ ] æ¨¡å‹ä¸‹è½½å®Œæˆï¼ˆcheckpoints ç›®å½•çº¦ 15GBï¼‰
- [ ] API æœåŠ¡å¯åŠ¨æˆåŠŸï¼ˆPM2 çŠ¶æ€æ˜¾ç¤º onlineï¼‰
- [ ] å¥åº·æ£€æŸ¥è¿”å› `model_loaded: true`
- [ ] æµ‹è¯• TTS ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
- [ ] æ•°æ®åº“è¿ç§»æ‰§è¡ŒæˆåŠŸ
- [ ] åç«¯æœåŠ¡é‡å¯å®Œæˆ

---

## ğŸ“Š ç›‘æ§å‘½ä»¤

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
pm2 status

# æŸ¥çœ‹ IndexTTS2 æ—¥å¿—
pm2 logs indextts2 --lines 100

# æŸ¥çœ‹åç«¯æ—¥å¿—
pm2 logs backend --lines 100

# å®æ—¶ç›‘æ§ GPU
nvidia-smi -l 1

# æŸ¥çœ‹ GPU å†…å­˜ä½¿ç”¨
nvidia-smi --query-gpu=memory.used,memory.total --format=csv
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### é—®é¢˜ 1: uv å‘½ä»¤æ‰¾ä¸åˆ°
```bash
# é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
export PATH="$HOME/.cargo/bin:$PATH"
source ~/.bashrc
```

### é—®é¢˜ 2: æ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
# ä½¿ç”¨é•œåƒåŠ é€Ÿ
export HF_ENDPOINT="https://hf-mirror.com"

# é‡æ–°ä¸‹è½½
cd /workspace/index-tts
hf download IndexTeam/IndexTTS-2 --local-dir=checkpoints
```

### é—®é¢˜ 3: CUDA å†…å­˜ä¸è¶³
```bash
# åœæ­¢å…¶ä»– GPU è¿›ç¨‹
pm2 stop comfyui

# é‡å¯ IndexTTS2
pm2 restart indextts2
```

### é—®é¢˜ 4: æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
pm2 logs indextts2 --lines 200

# æ£€æŸ¥ PyTorch æ˜¯å¦è¯†åˆ« GPU
cd /workspace/index-tts
uv run python3 -c "import torch; print('CUDA:', torch.cuda.is_available())"
```

---

## ğŸ‰ æµ‹è¯•å£°éŸ³å…‹éš†

éƒ¨ç½²å®Œæˆåï¼Œåœ¨ç½‘ç«™ä¸Šï¼š

1. **ä¸Šä¼ å£°éŸ³æ–‡ä»¶** - é€‰æ‹©ä¸€ä¸ªæ¸…æ™°çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆ3-10ç§’ï¼‰
2. **ç­‰å¾…å¤„ç†** - çº¦ 10-30 ç§’åçŠ¶æ€å˜ä¸º "ready"
3. **ç‚¹å‡»è¯•å¬** - è¾“å…¥æµ‹è¯•æ–‡æœ¬ï¼Œç‚¹å‡»"è¯•å¬"æŒ‰é’®
4. **å¬åˆ°å…‹éš†çš„å£°éŸ³** - åº”è¯¥èƒ½å¬åˆ°ä½ ä¸Šä¼ çš„å£°éŸ³ç‰¹å¾

---

## ğŸ“– å®Œæ•´æ–‡æ¡£

è¯¦ç»†çš„ API æ–‡æ¡£å’Œæ•…éšœæ’æŸ¥è¯·æŸ¥çœ‹ï¼š
ğŸ‘‰ **DEPLOY_INDEXTTS2.md**
